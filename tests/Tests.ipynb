{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "201a8cd9-421b-45a3-9ece-585bac140c43",
   "metadata": {},
   "source": [
    "# Tests Notebook\n",
    "\n",
    "This notebook is reserved for tests during development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4264f945-cb6c-440b-8b01-a627c2027a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.        0.7310586 1.761594  2.8577223 3.928055 ]\n"
     ]
    }
   ],
   "source": [
    "# Successful installation of JAX test\n",
    "from jax.nn import silu\n",
    "import jax.numpy as jnp\n",
    "\n",
    "x = jnp.arange(5.0)\n",
    "print(silu(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a739459-acaf-4c53-909f-bc11aecb976f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eae283b3-dd0a-4ee7-a09f-ca3a5a73f924",
   "metadata": {},
   "source": [
    "## Testing Splines\n",
    "\n",
    "Let's test the generation of spline basis functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f48357b4-7000-487f-b358-fdc5ddd6ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "path_to_src = os.path.abspath(os.path.join(os.getcwd(), '../src'))\n",
    "if path_to_src not in sys.path:\n",
    "    sys.path.append(path_to_src)\n",
    "\n",
    "from bases.splines import get_spline_basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655cb6b7-e665-454a-bc69-d9b174f255ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dae57a2-dc61-49dc-b04a-05c7f7fc5b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a6de11-b138-4fe7-9638-5f238e6c5ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "path_to_src = os.path.abspath(os.path.join(os.getcwd(), '../src'))\n",
    "if path_to_src not in sys.path:\n",
    "    sys.path.append(path_to_src)\n",
    "\n",
    "from KANLayer import KANLayer as kan\n",
    "from KAN import KAN\n",
    "import jax\n",
    "from jax import numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a5612e-b8dc-4402-84f2-802c195cf204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict_hierarchy(d, indent=0):\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, dict):\n",
    "            print(' ' * indent + str(key))\n",
    "            print_dict_hierarchy(value, indent + 4)\n",
    "        else:\n",
    "            print(' ' * indent + f\"{key}: shape {value.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ed42fc7-446f-482b-b3d8-84ac94140455",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "layer_dims = [4, 5, 2, 1]\n",
    "model = KAN(layer_dims=layer_dims, k=3, add_bias=True)\n",
    "\n",
    "x = jax.random.normal(key, (50, 4))\n",
    "\n",
    "variables = model.init(key, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc29160e-d114-41c6-8f60-fab011d6c313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the trainable parameters and non-trainable state\n",
    "print(\"Trainable parameters:\")\n",
    "print(variables['params'])\n",
    "\n",
    "print(\"\\nNon-trainable state variables:\")\n",
    "print(variables['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09238923-c8cf-44d0-9d4e-b7b9594da790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params\n",
      "    bias_0: shape (5,)\n",
      "    bias_1: shape (2,)\n",
      "    bias_2: shape (1,)\n",
      "    layers_0\n",
      "        c_basis: shape (20, 6)\n",
      "        c_spl: shape (20,)\n",
      "        c_res: shape (20,)\n",
      "    layers_1\n",
      "        c_basis: shape (10, 6)\n",
      "        c_spl: shape (10,)\n",
      "        c_res: shape (10,)\n",
      "    layers_2\n",
      "        c_basis: shape (2, 6)\n",
      "        c_spl: shape (2,)\n",
      "        c_res: shape (2,)\n",
      "state\n",
      "    layers_0\n",
      "        grid: shape (20, 10)\n",
      "    layers_1\n",
      "        grid: shape (10, 10)\n",
      "    layers_2\n",
      "        grid: shape (2, 10)\n"
     ]
    }
   ],
   "source": [
    "print_dict_hierarchy(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42b062c5-7013-4269-83ef-ee2674a54a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.21964498, -0.03216682, -0.02803302, -0.04404335,  0.10697184,\n",
       "         0.00917037],\n",
       "       [-0.07214645, -0.03873394, -0.09372874,  0.03438126,  0.07394429,\n",
       "        -0.19368024],\n",
       "       [ 0.144917  ,  0.07064237, -0.09206957,  0.09779473, -0.07791757,\n",
       "        -0.11313559],\n",
       "       [-0.08380805, -0.00183191,  0.01103233, -0.13060333, -0.03279752,\n",
       "         0.00528648],\n",
       "       [-0.03939278, -0.13313794, -0.02944968, -0.02043018,  0.04978757,\n",
       "         0.06520142],\n",
       "       [ 0.05189328, -0.07971673, -0.10149919,  0.08816522,  0.02823404,\n",
       "         0.14567198],\n",
       "       [-0.04320967,  0.00129707,  0.06899355,  0.01118089,  0.18311459,\n",
       "        -0.07600819],\n",
       "       [-0.07420332,  0.09264632,  0.02440042,  0.03857328,  0.01935199,\n",
       "        -0.12175804],\n",
       "       [ 0.01394208,  0.12633352,  0.11282189,  0.07304362, -0.09317457,\n",
       "        -0.00676571],\n",
       "       [-0.11424935,  0.07237625,  0.03601482,  0.12565634,  0.04958436,\n",
       "         0.19709854]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables['params']['layers_1']['c_basis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7397c40-2551-4b6c-be39-333c758aa703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bafde131-58de-4fe9-bd7b-82a5cdd9d382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform grid updates\n",
    "new_grid_size = 5\n",
    "updated_variables = model.apply(variables, x, new_grid_size, method=model.update_grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55961e63-fe47-434d-a22e-b0238991ff6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params\n",
      "    bias_0: shape (5,)\n",
      "    bias_1: shape (2,)\n",
      "    bias_2: shape (1,)\n",
      "    layers_0\n",
      "        c_basis: shape (20, 8)\n",
      "        c_spl: shape (20,)\n",
      "        c_res: shape (20,)\n",
      "    layers_1\n",
      "        c_basis: shape (10, 8)\n",
      "        c_spl: shape (10,)\n",
      "        c_res: shape (10,)\n",
      "    layers_2\n",
      "        c_basis: shape (2, 8)\n",
      "        c_spl: shape (2,)\n",
      "        c_res: shape (2,)\n",
      "state\n",
      "    layers_0\n",
      "        grid: shape (20, 12)\n",
      "    layers_1\n",
      "        grid: shape (10, 12)\n",
      "    layers_2\n",
      "        grid: shape (2, 12)\n"
     ]
    }
   ],
   "source": [
    "print_dict_hierarchy(updated_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8b48da9-fa31-4b3e-9fe2-b2712807b531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.02999173, -0.03370977, -0.03347092, -0.02784294, -0.01343204,\n",
       "         0.02792049,  0.07179645,  0.06490941],\n",
       "       [-0.07054527, -0.0504249 , -0.02268857,  0.0041829 ,  0.02827478,\n",
       "         0.05501393,  0.04043134, -0.07338444],\n",
       "       [-0.04324958, -0.02404464,  0.00513026,  0.03018621,  0.04226551,\n",
       "         0.01231476, -0.05553922, -0.08770344],\n",
       "       [-0.00731817, -0.03688883, -0.06182383, -0.08282282, -0.09563003,\n",
       "        -0.08224212, -0.03881234, -0.017495  ],\n",
       "       [-0.04516727, -0.03153471, -0.02297354, -0.01604484, -0.00534422,\n",
       "         0.01625229,  0.04225967,  0.05475741],\n",
       "       [-0.07709993, -0.03993033, -0.00081709,  0.03031873,  0.05473555,\n",
       "         0.05968446,  0.0495641 ,  0.07461052],\n",
       "       [ 0.05258897,  0.04627253,  0.04096211,  0.04042412,  0.05307961,\n",
       "         0.09784878,  0.1403644 ,  0.03437333],\n",
       "       [ 0.03864328,  0.03307077,  0.03224307,  0.03306453,  0.0332961 ,\n",
       "         0.02891284,  0.00801342, -0.04001885],\n",
       "       [ 0.10859791,  0.10073279,  0.08819524,  0.07285822,  0.04660345,\n",
       "        -0.01140373, -0.06542934, -0.04511216],\n",
       "       [ 0.05236961,  0.0684239 ,  0.08531803,  0.09676848,  0.09964931,\n",
       "         0.08751094,  0.07598681,  0.1184814 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_variables['params']['layers_1']['c_basis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35e8e7c8-f886-40f9-92e6-feb847ccda01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.21964498, -0.03216682, -0.02803302, -0.04404335,  0.10697184,\n",
       "         0.00917037],\n",
       "       [-0.07214645, -0.03873394, -0.09372874,  0.03438126,  0.07394429,\n",
       "        -0.19368024],\n",
       "       [ 0.144917  ,  0.07064237, -0.09206957,  0.09779473, -0.07791757,\n",
       "        -0.11313559],\n",
       "       [-0.08380805, -0.00183191,  0.01103233, -0.13060333, -0.03279752,\n",
       "         0.00528648],\n",
       "       [-0.03939278, -0.13313794, -0.02944968, -0.02043018,  0.04978757,\n",
       "         0.06520142],\n",
       "       [ 0.05189328, -0.07971673, -0.10149919,  0.08816522,  0.02823404,\n",
       "         0.14567198],\n",
       "       [-0.04320967,  0.00129707,  0.06899355,  0.01118089,  0.18311459,\n",
       "        -0.07600819],\n",
       "       [-0.07420332,  0.09264632,  0.02440042,  0.03857328,  0.01935199,\n",
       "        -0.12175804],\n",
       "       [ 0.01394208,  0.12633352,  0.11282189,  0.07304362, -0.09317457,\n",
       "        -0.00676571],\n",
       "       [-0.11424935,  0.07237625,  0.03601482,  0.12565634,  0.04958436,\n",
       "         0.19709854]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables['params']['layers_1']['c_basis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9459b9e8-07d9-4a99-86b6-eeb2651377c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, spl_regs = model.apply(variables, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3f01abb-3331-4a74-ab5b-c17acf031a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array([[0.00683656, 0.00996755, 0.01660573, 0.00698722],\n",
       "        [0.01234719, 0.00844338, 0.01165444, 0.00359057],\n",
       "        [0.00864134, 0.00688513, 0.00845095, 0.01252255],\n",
       "        [0.00697956, 0.00756933, 0.00858223, 0.010777  ],\n",
       "        [0.01196445, 0.00689442, 0.00360187, 0.01110468]], dtype=float32),\n",
       " Array([[0.00437403, 0.00439544, 0.00362973, 0.01215728, 0.00293692],\n",
       "        [0.00585498, 0.00946443, 0.00511737, 0.00995341, 0.01484072]],      dtype=float32),\n",
       " Array([[0.00335365, 0.01805771]], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spl_regs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47908625-4b6e-459a-9bf7-7c14295e9f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c735c373-122c-4d3d-a18c-4e69e9e6ae92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4eb435a-6fdd-48dc-8dc2-7492638e6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def create_dataset(f, \n",
    "                   n_var=2, \n",
    "                   ranges = [-1,1],\n",
    "                   train_num=1000, \n",
    "                   test_num=1000,\n",
    "                   normalize_input=False,\n",
    "                   normalize_label=False,\n",
    "                   device='cpu',\n",
    "                   seed=0):\n",
    "    '''\n",
    "    create dataset\n",
    "    \n",
    "    Args:\n",
    "    -----\n",
    "        f : function\n",
    "            the symbolic formula used to create the synthetic dataset\n",
    "        ranges : list or np.array; shape (2,) or (n_var, 2)\n",
    "            the range of input variables. Default: [-1,1].\n",
    "        train_num : int\n",
    "            the number of training samples. Default: 1000.\n",
    "        test_num : int\n",
    "            the number of test samples. Default: 1000.\n",
    "        normalize_input : bool\n",
    "            If True, apply normalization to inputs. Default: False.\n",
    "        normalize_label : bool\n",
    "            If True, apply normalization to labels. Default: False.\n",
    "        device : str\n",
    "            device. Default: 'cpu'.\n",
    "        seed : int\n",
    "            random seed. Default: 0.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "        dataset : dic\n",
    "            Train/test inputs/labels are dataset['train_input'], dataset['train_label'],\n",
    "                        dataset['test_input'], dataset['test_label']\n",
    "         \n",
    "    Example\n",
    "    -------\n",
    "    >>> f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]]) + x[:,[1]]**2)\n",
    "    >>> dataset = create_dataset(f, n_var=2, train_num=100)\n",
    "    >>> dataset['train_input'].shape\n",
    "    torch.Size([100, 2])\n",
    "    '''\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    if len(np.array(ranges).shape) == 1:\n",
    "        ranges = np.array(ranges * n_var).reshape(n_var,2)\n",
    "    else:\n",
    "        ranges = np.array(ranges)\n",
    "        \n",
    "    train_input = torch.zeros(train_num, n_var)\n",
    "    test_input = torch.zeros(test_num, n_var)\n",
    "    for i in range(n_var):\n",
    "        train_input[:,i] = torch.rand(train_num,)*(ranges[i,1]-ranges[i,0])+ranges[i,0]\n",
    "        test_input[:,i] = torch.rand(test_num,)*(ranges[i,1]-ranges[i,0])+ranges[i,0]\n",
    "        \n",
    "        \n",
    "    train_label = f(train_input)\n",
    "    test_label = f(test_input)\n",
    "        \n",
    "        \n",
    "    def normalize(data, mean, std):\n",
    "            return (data-mean)/std\n",
    "            \n",
    "    if normalize_input == True:\n",
    "        mean_input = torch.mean(train_input, dim=0, keepdim=True)\n",
    "        std_input = torch.std(train_input, dim=0, keepdim=True)\n",
    "        train_input = normalize(train_input, mean_input, std_input)\n",
    "        test_input = normalize(test_input, mean_input, std_input)\n",
    "        \n",
    "    if normalize_label == True:\n",
    "        mean_label = torch.mean(train_label, dim=0, keepdim=True)\n",
    "        std_label = torch.std(train_label, dim=0, keepdim=True)\n",
    "        train_label = normalize(train_label, mean_label, std_label)\n",
    "        test_label = normalize(test_label, mean_label, std_label)\n",
    "\n",
    "    dataset = {}\n",
    "    dataset['train_input'] = train_input.to(device)\n",
    "    dataset['test_input'] = test_input.to(device)\n",
    "\n",
    "    dataset['train_label'] = train_label.to(device)\n",
    "    dataset['test_label'] = test_label.to(device)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "350dc191-f489-470b-ab56-937b55a0dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]]) + x[:,[1]]**2)\n",
    "dataset = create_dataset(f, n_var=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04a005d7-8155-4aa7-9faa-739953a7fadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0075,  0.5547,  0.4975,  0.9488],\n",
       "        [ 0.5364,  0.1791, -0.2652, -0.4505],\n",
       "        [-0.8230,  0.1526,  0.7550, -0.6354],\n",
       "        ...,\n",
       "        [-0.3216, -0.4567, -0.4248,  0.5234],\n",
       "        [ 0.0036, -0.3966,  0.0332,  0.2307],\n",
       "        [-0.1923, -0.8376, -0.7736,  0.6485]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a96eced-d511-4c4e-b850-0a25d1c8b606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3287],\n",
       "        [2.7886],\n",
       "        [0.6038],\n",
       "        [0.6248],\n",
       "        [0.5784],\n",
       "        [2.4956],\n",
       "        [0.9510],\n",
       "        [2.2221],\n",
       "        [0.9604],\n",
       "        [5.0185],\n",
       "        [0.7090],\n",
       "        [0.6934],\n",
       "        [1.4567],\n",
       "        [0.4631],\n",
       "        [0.6223],\n",
       "        [1.1396],\n",
       "        [2.6025],\n",
       "        [3.8784],\n",
       "        [0.7173],\n",
       "        [0.5919],\n",
       "        [5.1320],\n",
       "        [2.4276],\n",
       "        [0.5478],\n",
       "        [2.5004],\n",
       "        [0.6470],\n",
       "        [1.3875],\n",
       "        [2.6785],\n",
       "        [0.9634],\n",
       "        [0.4302],\n",
       "        [0.7583],\n",
       "        [0.4161],\n",
       "        [3.7847],\n",
       "        [0.4791],\n",
       "        [0.3708],\n",
       "        [0.4698],\n",
       "        [1.0199],\n",
       "        [0.4410],\n",
       "        [2.0350],\n",
       "        [4.1370],\n",
       "        [2.7261],\n",
       "        [1.2566],\n",
       "        [0.3683],\n",
       "        [2.6944],\n",
       "        [2.1286],\n",
       "        [0.5894],\n",
       "        [0.3798],\n",
       "        [3.8286],\n",
       "        [3.1215],\n",
       "        [0.4911],\n",
       "        [0.9707],\n",
       "        [3.7596],\n",
       "        [1.2254],\n",
       "        [2.6039],\n",
       "        [1.6970],\n",
       "        [2.3876],\n",
       "        [0.3825],\n",
       "        [3.6246],\n",
       "        [1.1597],\n",
       "        [0.7954],\n",
       "        [0.4213],\n",
       "        [3.1205],\n",
       "        [3.0022],\n",
       "        [0.3908],\n",
       "        [2.3999],\n",
       "        [2.8620],\n",
       "        [1.7526],\n",
       "        [2.8243],\n",
       "        [2.2464],\n",
       "        [3.9829],\n",
       "        [1.4334],\n",
       "        [0.5372],\n",
       "        [0.5820],\n",
       "        [4.5535],\n",
       "        [2.5497],\n",
       "        [2.9870],\n",
       "        [1.8298],\n",
       "        [1.8510],\n",
       "        [0.8739],\n",
       "        [1.3922],\n",
       "        [0.4925],\n",
       "        [0.9414],\n",
       "        [2.2063],\n",
       "        [3.9714],\n",
       "        [1.8758],\n",
       "        [1.7694],\n",
       "        [0.6040],\n",
       "        [0.7815],\n",
       "        [0.6033],\n",
       "        [3.5345],\n",
       "        [0.4517],\n",
       "        [4.5851],\n",
       "        [5.5120],\n",
       "        [4.7917],\n",
       "        [4.5670],\n",
       "        [0.9869],\n",
       "        [0.4453],\n",
       "        [3.1086],\n",
       "        [1.9792],\n",
       "        [0.9516],\n",
       "        [0.8477],\n",
       "        [3.2458],\n",
       "        [2.3735],\n",
       "        [0.3780],\n",
       "        [0.5183],\n",
       "        [1.3717],\n",
       "        [1.9279],\n",
       "        [0.5049],\n",
       "        [0.5866],\n",
       "        [1.4630],\n",
       "        [2.3376],\n",
       "        [0.3955],\n",
       "        [2.8069],\n",
       "        [0.3904],\n",
       "        [2.9486],\n",
       "        [2.3328],\n",
       "        [0.6480],\n",
       "        [1.0123],\n",
       "        [1.5349],\n",
       "        [2.6224],\n",
       "        [1.9725],\n",
       "        [2.5802],\n",
       "        [1.4031],\n",
       "        [0.5676],\n",
       "        [2.7211],\n",
       "        [0.9526],\n",
       "        [0.5045],\n",
       "        [0.9555],\n",
       "        [0.5461],\n",
       "        [0.7154],\n",
       "        [1.2994],\n",
       "        [0.6104],\n",
       "        [1.8893],\n",
       "        [0.8458],\n",
       "        [0.9167],\n",
       "        [3.3482],\n",
       "        [0.8748],\n",
       "        [2.1007],\n",
       "        [1.5905],\n",
       "        [3.6545],\n",
       "        [3.0896],\n",
       "        [1.8230],\n",
       "        [6.2184],\n",
       "        [2.4803],\n",
       "        [1.2560],\n",
       "        [0.9356],\n",
       "        [0.3700],\n",
       "        [2.3990],\n",
       "        [1.0680],\n",
       "        [0.9034],\n",
       "        [0.5186],\n",
       "        [1.4557],\n",
       "        [1.1299],\n",
       "        [0.7087],\n",
       "        [2.7443],\n",
       "        [2.8680],\n",
       "        [1.6206],\n",
       "        [2.9722],\n",
       "        [1.4321],\n",
       "        [0.6403],\n",
       "        [0.4118],\n",
       "        [0.9708],\n",
       "        [0.5612],\n",
       "        [0.8963],\n",
       "        [0.6801],\n",
       "        [1.2417],\n",
       "        [1.1171],\n",
       "        [0.4013],\n",
       "        [2.5353],\n",
       "        [0.7424],\n",
       "        [1.1772],\n",
       "        [2.5776],\n",
       "        [0.4949],\n",
       "        [3.4453],\n",
       "        [2.5787],\n",
       "        [0.7592],\n",
       "        [3.2631],\n",
       "        [1.0073],\n",
       "        [0.3837],\n",
       "        [2.1429],\n",
       "        [0.5826],\n",
       "        [1.5882],\n",
       "        [0.5515],\n",
       "        [3.0676],\n",
       "        [4.1947],\n",
       "        [3.4516],\n",
       "        [4.3782],\n",
       "        [0.5125],\n",
       "        [0.5638],\n",
       "        [0.6592],\n",
       "        [2.8497],\n",
       "        [2.1445],\n",
       "        [2.5079],\n",
       "        [0.4825],\n",
       "        [1.3638],\n",
       "        [0.4573],\n",
       "        [0.3950],\n",
       "        [0.3836],\n",
       "        [3.8050],\n",
       "        [0.3937],\n",
       "        [1.2875],\n",
       "        [1.5050],\n",
       "        [3.8098],\n",
       "        [0.9436],\n",
       "        [0.5094],\n",
       "        [0.7907],\n",
       "        [3.8956],\n",
       "        [1.0767],\n",
       "        [1.6088],\n",
       "        [3.6575],\n",
       "        [3.0878],\n",
       "        [0.9865],\n",
       "        [0.7070],\n",
       "        [2.4757],\n",
       "        [0.9613],\n",
       "        [1.9481],\n",
       "        [2.1258],\n",
       "        [1.1446],\n",
       "        [0.4020],\n",
       "        [2.5710],\n",
       "        [0.8899],\n",
       "        [1.5965],\n",
       "        [1.3247],\n",
       "        [2.5134],\n",
       "        [1.1192],\n",
       "        [0.6857],\n",
       "        [5.3294],\n",
       "        [0.8732],\n",
       "        [0.7940],\n",
       "        [1.1029],\n",
       "        [0.7441],\n",
       "        [1.2632],\n",
       "        [1.7193],\n",
       "        [1.5997],\n",
       "        [1.4279],\n",
       "        [6.9251],\n",
       "        [0.6569],\n",
       "        [7.1564],\n",
       "        [0.5818],\n",
       "        [0.9861],\n",
       "        [2.3924],\n",
       "        [2.3802],\n",
       "        [3.8229],\n",
       "        [0.9198],\n",
       "        [1.6146],\n",
       "        [2.8959],\n",
       "        [1.2660],\n",
       "        [2.5465],\n",
       "        [0.5970],\n",
       "        [1.0444],\n",
       "        [0.9215],\n",
       "        [0.3694],\n",
       "        [3.8026],\n",
       "        [3.1777],\n",
       "        [0.8069],\n",
       "        [0.3878],\n",
       "        [0.3996],\n",
       "        [1.3114],\n",
       "        [3.0012],\n",
       "        [0.4344],\n",
       "        [0.8755],\n",
       "        [0.3797],\n",
       "        [4.1716],\n",
       "        [5.5051],\n",
       "        [2.0031],\n",
       "        [3.3026],\n",
       "        [0.8934],\n",
       "        [0.4795],\n",
       "        [3.2369],\n",
       "        [1.7354],\n",
       "        [2.9362],\n",
       "        [0.7002],\n",
       "        [0.4588],\n",
       "        [0.9145],\n",
       "        [1.9813],\n",
       "        [0.3749],\n",
       "        [0.9948],\n",
       "        [1.5296],\n",
       "        [0.5796],\n",
       "        [0.8154],\n",
       "        [2.3503],\n",
       "        [1.2775],\n",
       "        [0.4301],\n",
       "        [0.5776],\n",
       "        [1.8248],\n",
       "        [1.7491],\n",
       "        [3.0009],\n",
       "        [0.9997],\n",
       "        [2.5571],\n",
       "        [0.6988],\n",
       "        [0.8762],\n",
       "        [0.4210],\n",
       "        [2.4430],\n",
       "        [3.5022],\n",
       "        [0.9535],\n",
       "        [0.5555],\n",
       "        [0.3962],\n",
       "        [2.3306],\n",
       "        [0.5571],\n",
       "        [4.1596],\n",
       "        [1.0276],\n",
       "        [0.4383],\n",
       "        [3.8194],\n",
       "        [0.4321],\n",
       "        [2.8119],\n",
       "        [4.3768],\n",
       "        [1.0825],\n",
       "        [2.3044],\n",
       "        [3.7501],\n",
       "        [4.3977],\n",
       "        [0.7497],\n",
       "        [0.6229],\n",
       "        [1.1800],\n",
       "        [5.7268],\n",
       "        [0.6873],\n",
       "        [2.8136],\n",
       "        [3.7291],\n",
       "        [0.3913],\n",
       "        [1.1148],\n",
       "        [3.0784],\n",
       "        [1.2911],\n",
       "        [1.6188],\n",
       "        [3.1485],\n",
       "        [1.1257],\n",
       "        [1.2915],\n",
       "        [4.9981],\n",
       "        [1.3626],\n",
       "        [2.6290],\n",
       "        [2.3524],\n",
       "        [2.7065],\n",
       "        [0.4008],\n",
       "        [0.6426],\n",
       "        [0.9012],\n",
       "        [1.4803],\n",
       "        [5.5317],\n",
       "        [0.4383],\n",
       "        [2.8239],\n",
       "        [2.0149],\n",
       "        [2.5687],\n",
       "        [1.5232],\n",
       "        [2.9324],\n",
       "        [0.5316],\n",
       "        [0.4435],\n",
       "        [1.7364],\n",
       "        [6.8273],\n",
       "        [0.3873],\n",
       "        [2.9301],\n",
       "        [2.7633],\n",
       "        [3.0906],\n",
       "        [0.6810],\n",
       "        [3.0302],\n",
       "        [0.4104],\n",
       "        [1.9831],\n",
       "        [0.7159],\n",
       "        [5.9981],\n",
       "        [1.7022],\n",
       "        [2.8285],\n",
       "        [0.6340],\n",
       "        [3.0417],\n",
       "        [0.5214],\n",
       "        [2.7539],\n",
       "        [0.4494],\n",
       "        [0.9625],\n",
       "        [1.0657],\n",
       "        [3.5390],\n",
       "        [4.3470],\n",
       "        [1.2193],\n",
       "        [2.0998],\n",
       "        [0.7215],\n",
       "        [0.9419],\n",
       "        [0.6233],\n",
       "        [0.8480],\n",
       "        [2.7895],\n",
       "        [1.1616],\n",
       "        [0.3863],\n",
       "        [1.0897],\n",
       "        [0.4608],\n",
       "        [1.7239],\n",
       "        [3.7302],\n",
       "        [4.3593],\n",
       "        [2.6469],\n",
       "        [2.9940],\n",
       "        [0.5892],\n",
       "        [2.9921],\n",
       "        [1.5567],\n",
       "        [2.9949],\n",
       "        [1.0394],\n",
       "        [2.8199],\n",
       "        [6.4675],\n",
       "        [0.5238],\n",
       "        [3.1142],\n",
       "        [1.4271],\n",
       "        [0.6372],\n",
       "        [0.8032],\n",
       "        [0.5612],\n",
       "        [0.5368],\n",
       "        [6.1965],\n",
       "        [5.5799],\n",
       "        [0.8930],\n",
       "        [0.5424],\n",
       "        [3.2775],\n",
       "        [6.2919],\n",
       "        [1.2604],\n",
       "        [0.5302],\n",
       "        [1.7909],\n",
       "        [2.7258],\n",
       "        [0.5057],\n",
       "        [1.5005],\n",
       "        [4.0689],\n",
       "        [0.6252],\n",
       "        [2.6995],\n",
       "        [0.6357],\n",
       "        [1.6466],\n",
       "        [1.5787],\n",
       "        [1.3179],\n",
       "        [0.5277],\n",
       "        [0.9218],\n",
       "        [0.6117],\n",
       "        [0.6514],\n",
       "        [2.7678],\n",
       "        [1.6199],\n",
       "        [1.1906],\n",
       "        [0.7886],\n",
       "        [3.1432],\n",
       "        [2.9976],\n",
       "        [3.3985],\n",
       "        [0.7968],\n",
       "        [1.2826],\n",
       "        [0.6771],\n",
       "        [0.3820],\n",
       "        [2.4757],\n",
       "        [0.4846],\n",
       "        [2.5887],\n",
       "        [1.5843],\n",
       "        [1.6211],\n",
       "        [1.0775],\n",
       "        [0.8114],\n",
       "        [4.3023],\n",
       "        [0.5682],\n",
       "        [3.0540],\n",
       "        [0.7610],\n",
       "        [0.9666],\n",
       "        [1.0778],\n",
       "        [0.5559],\n",
       "        [3.5753],\n",
       "        [1.4947],\n",
       "        [4.1898],\n",
       "        [0.4153],\n",
       "        [2.2568],\n",
       "        [1.6793],\n",
       "        [0.9436],\n",
       "        [1.7491],\n",
       "        [3.2224],\n",
       "        [1.1914],\n",
       "        [3.1122],\n",
       "        [0.7798],\n",
       "        [2.1422],\n",
       "        [2.0641],\n",
       "        [2.7761],\n",
       "        [1.3803],\n",
       "        [0.4780],\n",
       "        [0.9629],\n",
       "        [0.3966],\n",
       "        [2.7663],\n",
       "        [0.6844],\n",
       "        [3.6764],\n",
       "        [2.8552],\n",
       "        [1.5468],\n",
       "        [0.4303],\n",
       "        [0.7647],\n",
       "        [0.7612],\n",
       "        [3.5167],\n",
       "        [1.9240],\n",
       "        [6.2919],\n",
       "        [0.7557],\n",
       "        [3.7933],\n",
       "        [1.2007],\n",
       "        [1.5167],\n",
       "        [3.4809],\n",
       "        [0.8501],\n",
       "        [3.2928],\n",
       "        [0.6488],\n",
       "        [0.3772],\n",
       "        [0.6513],\n",
       "        [2.7291],\n",
       "        [1.5599],\n",
       "        [4.4974],\n",
       "        [3.0522],\n",
       "        [2.7151],\n",
       "        [1.5916],\n",
       "        [0.4382],\n",
       "        [1.2237],\n",
       "        [1.6095],\n",
       "        [3.4057],\n",
       "        [1.1418],\n",
       "        [3.1501],\n",
       "        [0.7259],\n",
       "        [0.8246],\n",
       "        [0.8592],\n",
       "        [2.3636],\n",
       "        [1.5619],\n",
       "        [0.9426],\n",
       "        [3.1982],\n",
       "        [4.3723],\n",
       "        [4.3399],\n",
       "        [1.9221],\n",
       "        [0.5414],\n",
       "        [2.4026],\n",
       "        [5.3509],\n",
       "        [0.6962],\n",
       "        [3.1682],\n",
       "        [0.4618],\n",
       "        [2.8114],\n",
       "        [0.8548],\n",
       "        [0.4285],\n",
       "        [4.0558],\n",
       "        [2.6865],\n",
       "        [0.3829],\n",
       "        [2.6800],\n",
       "        [2.7090],\n",
       "        [0.9810],\n",
       "        [2.3548],\n",
       "        [0.5716],\n",
       "        [4.6620],\n",
       "        [0.7051],\n",
       "        [0.4705],\n",
       "        [0.9787],\n",
       "        [2.0654],\n",
       "        [0.8576],\n",
       "        [0.9917],\n",
       "        [0.3842],\n",
       "        [1.1748],\n",
       "        [1.5816],\n",
       "        [0.5068],\n",
       "        [0.6873],\n",
       "        [1.0476],\n",
       "        [1.7353],\n",
       "        [0.6245],\n",
       "        [0.4495],\n",
       "        [0.4058],\n",
       "        [2.7585],\n",
       "        [0.7489],\n",
       "        [4.1773],\n",
       "        [0.8436],\n",
       "        [0.4415],\n",
       "        [2.4609],\n",
       "        [3.6670],\n",
       "        [0.4297],\n",
       "        [1.6312],\n",
       "        [0.4996],\n",
       "        [1.0711],\n",
       "        [0.8520],\n",
       "        [1.0931],\n",
       "        [1.6936],\n",
       "        [0.4017],\n",
       "        [4.2113],\n",
       "        [1.2736],\n",
       "        [1.4445],\n",
       "        [0.5364],\n",
       "        [2.4866],\n",
       "        [1.2951],\n",
       "        [1.4174],\n",
       "        [0.6214],\n",
       "        [0.6465],\n",
       "        [3.0185],\n",
       "        [0.4103],\n",
       "        [1.3027],\n",
       "        [0.7655],\n",
       "        [0.5905],\n",
       "        [2.6713],\n",
       "        [3.8260],\n",
       "        [1.7227],\n",
       "        [2.6405],\n",
       "        [0.5988],\n",
       "        [0.6509],\n",
       "        [0.8511],\n",
       "        [1.6759],\n",
       "        [0.8794],\n",
       "        [0.9346],\n",
       "        [3.7883],\n",
       "        [1.2401],\n",
       "        [1.2289],\n",
       "        [1.1529],\n",
       "        [0.7923],\n",
       "        [2.1138],\n",
       "        [0.8550],\n",
       "        [0.5526],\n",
       "        [4.6850],\n",
       "        [3.7525],\n",
       "        [2.0156],\n",
       "        [3.1182],\n",
       "        [0.8065],\n",
       "        [0.7023],\n",
       "        [1.4200],\n",
       "        [1.4787],\n",
       "        [7.1161],\n",
       "        [4.1667],\n",
       "        [1.7616],\n",
       "        [1.7677],\n",
       "        [1.3057],\n",
       "        [1.4281],\n",
       "        [1.5759],\n",
       "        [0.5119],\n",
       "        [0.4876],\n",
       "        [2.6433],\n",
       "        [0.3806],\n",
       "        [0.3731],\n",
       "        [2.9215],\n",
       "        [0.6010],\n",
       "        [0.3729],\n",
       "        [1.5032],\n",
       "        [1.4395],\n",
       "        [0.5364],\n",
       "        [4.2715],\n",
       "        [0.4017],\n",
       "        [5.7330],\n",
       "        [2.4156],\n",
       "        [2.8376],\n",
       "        [3.8226],\n",
       "        [3.0158],\n",
       "        [2.9483],\n",
       "        [0.4866],\n",
       "        [1.2370],\n",
       "        [2.5564],\n",
       "        [1.0250],\n",
       "        [0.4668],\n",
       "        [1.0484],\n",
       "        [2.4752],\n",
       "        [1.3145],\n",
       "        [0.7866],\n",
       "        [0.8250],\n",
       "        [2.7974],\n",
       "        [2.3686],\n",
       "        [4.8785],\n",
       "        [1.3373],\n",
       "        [2.5450],\n",
       "        [1.0695],\n",
       "        [0.4315],\n",
       "        [1.4825],\n",
       "        [0.4979],\n",
       "        [3.2545],\n",
       "        [0.4058],\n",
       "        [1.5659],\n",
       "        [2.3235],\n",
       "        [1.2811],\n",
       "        [0.4470],\n",
       "        [2.2591],\n",
       "        [0.3896],\n",
       "        [1.9355],\n",
       "        [0.8043],\n",
       "        [0.5276],\n",
       "        [3.3300],\n",
       "        [0.5047],\n",
       "        [3.8875],\n",
       "        [1.0026],\n",
       "        [0.6940],\n",
       "        [0.3730],\n",
       "        [1.6796],\n",
       "        [1.4844],\n",
       "        [0.5294],\n",
       "        [5.6886],\n",
       "        [0.9582],\n",
       "        [0.7133],\n",
       "        [3.3685],\n",
       "        [0.5385],\n",
       "        [1.3877],\n",
       "        [2.1777],\n",
       "        [0.6587],\n",
       "        [2.0304],\n",
       "        [0.4413],\n",
       "        [1.9700],\n",
       "        [0.9610],\n",
       "        [0.6476],\n",
       "        [0.6540],\n",
       "        [2.5185],\n",
       "        [4.9507],\n",
       "        [2.0720],\n",
       "        [0.9261],\n",
       "        [0.8948],\n",
       "        [2.3267],\n",
       "        [0.8483],\n",
       "        [3.1307],\n",
       "        [0.5174],\n",
       "        [0.8788],\n",
       "        [1.7836],\n",
       "        [6.8297],\n",
       "        [2.3348],\n",
       "        [1.5852],\n",
       "        [0.5993],\n",
       "        [3.1231],\n",
       "        [2.3681],\n",
       "        [6.6527],\n",
       "        [0.3932],\n",
       "        [3.1896],\n",
       "        [1.2608],\n",
       "        [1.7155],\n",
       "        [0.8141],\n",
       "        [4.6514],\n",
       "        [0.7223],\n",
       "        [2.3235],\n",
       "        [2.1453],\n",
       "        [0.4732],\n",
       "        [2.4313],\n",
       "        [0.7834],\n",
       "        [3.5661],\n",
       "        [0.7431],\n",
       "        [0.7194],\n",
       "        [1.5052],\n",
       "        [2.7180],\n",
       "        [0.6249],\n",
       "        [3.9107],\n",
       "        [0.8363],\n",
       "        [0.6834],\n",
       "        [1.6242],\n",
       "        [0.8823],\n",
       "        [2.4239],\n",
       "        [1.3374],\n",
       "        [1.5094],\n",
       "        [4.3287],\n",
       "        [2.7185],\n",
       "        [2.3177],\n",
       "        [2.2765],\n",
       "        [1.1934],\n",
       "        [0.6396],\n",
       "        [0.7629],\n",
       "        [0.3774],\n",
       "        [2.0030],\n",
       "        [1.3195],\n",
       "        [0.9287],\n",
       "        [4.9106],\n",
       "        [0.5952],\n",
       "        [0.6191],\n",
       "        [4.7308],\n",
       "        [1.2092],\n",
       "        [1.3265],\n",
       "        [0.6956],\n",
       "        [2.9107],\n",
       "        [1.3637],\n",
       "        [1.0219],\n",
       "        [5.0250],\n",
       "        [0.7314],\n",
       "        [0.5502],\n",
       "        [2.5007],\n",
       "        [1.9625],\n",
       "        [1.1118],\n",
       "        [3.0481],\n",
       "        [1.6458],\n",
       "        [2.5021],\n",
       "        [0.4067],\n",
       "        [0.8889],\n",
       "        [0.5814],\n",
       "        [0.5890],\n",
       "        [1.0171],\n",
       "        [2.0369],\n",
       "        [1.6082],\n",
       "        [2.3244],\n",
       "        [4.9860],\n",
       "        [0.4530],\n",
       "        [2.8145],\n",
       "        [0.5214],\n",
       "        [0.4410],\n",
       "        [1.7902],\n",
       "        [6.0177],\n",
       "        [0.9104],\n",
       "        [2.4183],\n",
       "        [2.5192],\n",
       "        [0.4637],\n",
       "        [0.7426],\n",
       "        [3.8524],\n",
       "        [0.5396],\n",
       "        [0.4522],\n",
       "        [3.0131],\n",
       "        [0.7862],\n",
       "        [3.3880],\n",
       "        [3.2173],\n",
       "        [3.0569],\n",
       "        [0.6389],\n",
       "        [1.8238],\n",
       "        [0.5589],\n",
       "        [1.0053],\n",
       "        [1.0928],\n",
       "        [1.6396],\n",
       "        [4.9235],\n",
       "        [1.4769],\n",
       "        [1.3677],\n",
       "        [0.3840],\n",
       "        [0.4251],\n",
       "        [0.5632],\n",
       "        [1.3979],\n",
       "        [1.5817],\n",
       "        [1.7482],\n",
       "        [1.2864],\n",
       "        [2.3617],\n",
       "        [2.3820],\n",
       "        [5.6422],\n",
       "        [0.5084],\n",
       "        [0.8950],\n",
       "        [0.6706],\n",
       "        [0.5959],\n",
       "        [1.0281],\n",
       "        [0.7007],\n",
       "        [3.2545],\n",
       "        [0.6335],\n",
       "        [1.8574],\n",
       "        [0.4555],\n",
       "        [1.0114],\n",
       "        [1.6494],\n",
       "        [1.2140],\n",
       "        [0.4191],\n",
       "        [1.7084],\n",
       "        [1.5205],\n",
       "        [0.3698],\n",
       "        [0.4298],\n",
       "        [2.4992],\n",
       "        [0.8645],\n",
       "        [1.6586],\n",
       "        [2.7023],\n",
       "        [0.8697],\n",
       "        [2.8088],\n",
       "        [0.8152],\n",
       "        [2.7549],\n",
       "        [1.3274],\n",
       "        [0.5796],\n",
       "        [2.7148],\n",
       "        [0.5175],\n",
       "        [1.3053],\n",
       "        [0.7436],\n",
       "        [1.2495],\n",
       "        [0.4120],\n",
       "        [1.9714],\n",
       "        [1.4452],\n",
       "        [2.6392],\n",
       "        [0.5526],\n",
       "        [1.6671],\n",
       "        [0.9377],\n",
       "        [1.0614],\n",
       "        [2.6292],\n",
       "        [1.4847],\n",
       "        [0.4123],\n",
       "        [0.4182],\n",
       "        [2.1158],\n",
       "        [0.6572],\n",
       "        [4.7018],\n",
       "        [2.4602],\n",
       "        [2.5273],\n",
       "        [2.9199],\n",
       "        [0.6363],\n",
       "        [6.3241],\n",
       "        [3.2612],\n",
       "        [1.1568],\n",
       "        [2.3761],\n",
       "        [1.3229],\n",
       "        [2.4400],\n",
       "        [0.6413],\n",
       "        [0.3712],\n",
       "        [2.6641],\n",
       "        [0.7556],\n",
       "        [1.2309],\n",
       "        [0.5683],\n",
       "        [2.8942],\n",
       "        [1.4265],\n",
       "        [2.5828],\n",
       "        [1.3404],\n",
       "        [2.0898],\n",
       "        [0.8451],\n",
       "        [1.1440],\n",
       "        [0.4673],\n",
       "        [1.1412],\n",
       "        [0.9166],\n",
       "        [0.7565],\n",
       "        [2.6569],\n",
       "        [2.1378],\n",
       "        [0.8253],\n",
       "        [2.4288],\n",
       "        [1.2088],\n",
       "        [0.9476],\n",
       "        [3.2033],\n",
       "        [1.9544],\n",
       "        [1.1225],\n",
       "        [0.4551],\n",
       "        [1.5203],\n",
       "        [0.4179],\n",
       "        [0.8177],\n",
       "        [0.5626],\n",
       "        [1.2184],\n",
       "        [2.8280],\n",
       "        [7.3336],\n",
       "        [3.0183],\n",
       "        [0.8718],\n",
       "        [2.9036],\n",
       "        [2.7142],\n",
       "        [0.3966],\n",
       "        [1.9363],\n",
       "        [2.1369],\n",
       "        [3.0253],\n",
       "        [0.3777],\n",
       "        [4.8166],\n",
       "        [0.7057],\n",
       "        [1.2358],\n",
       "        [4.2339],\n",
       "        [2.4529],\n",
       "        [3.3680],\n",
       "        [1.1231],\n",
       "        [1.7536],\n",
       "        [3.4808],\n",
       "        [2.2972],\n",
       "        [0.7116],\n",
       "        [0.5465],\n",
       "        [0.6485],\n",
       "        [0.7087],\n",
       "        [0.4112],\n",
       "        [2.7275],\n",
       "        [4.5692],\n",
       "        [2.3604],\n",
       "        [4.6615],\n",
       "        [1.7437],\n",
       "        [3.8348],\n",
       "        [1.5887],\n",
       "        [1.0594],\n",
       "        [4.6429],\n",
       "        [1.5742],\n",
       "        [3.5530],\n",
       "        [1.1013],\n",
       "        [1.7407],\n",
       "        [3.1019],\n",
       "        [2.5174],\n",
       "        [1.1416],\n",
       "        [3.1410],\n",
       "        [1.3729],\n",
       "        [3.5124],\n",
       "        [2.3144],\n",
       "        [1.0429],\n",
       "        [1.9662],\n",
       "        [1.5730],\n",
       "        [2.3948],\n",
       "        [1.6806],\n",
       "        [4.8130],\n",
       "        [4.6874],\n",
       "        [0.7783],\n",
       "        [3.0821],\n",
       "        [0.8489],\n",
       "        [3.0225],\n",
       "        [0.4887],\n",
       "        [0.3926],\n",
       "        [1.8977],\n",
       "        [0.4139],\n",
       "        [0.7756],\n",
       "        [1.6665],\n",
       "        [0.9360],\n",
       "        [3.0125],\n",
       "        [0.3817],\n",
       "        [0.4085],\n",
       "        [0.3913],\n",
       "        [0.7963],\n",
       "        [1.0452],\n",
       "        [5.8809],\n",
       "        [4.2745],\n",
       "        [1.5014],\n",
       "        [0.4395],\n",
       "        [2.4759],\n",
       "        [1.7839],\n",
       "        [0.6983],\n",
       "        [2.4729],\n",
       "        [1.3687],\n",
       "        [2.5004],\n",
       "        [1.2358],\n",
       "        [2.3396],\n",
       "        [3.5386],\n",
       "        [0.3923],\n",
       "        [2.6815],\n",
       "        [2.5086],\n",
       "        [3.5745],\n",
       "        [2.5783],\n",
       "        [2.1655],\n",
       "        [2.4596],\n",
       "        [0.4212],\n",
       "        [1.6425],\n",
       "        [4.4343],\n",
       "        [1.4667],\n",
       "        [1.0082],\n",
       "        [4.0066],\n",
       "        [0.7134],\n",
       "        [1.2455],\n",
       "        [1.9595],\n",
       "        [0.8223],\n",
       "        [3.8660],\n",
       "        [0.4524],\n",
       "        [0.4959],\n",
       "        [1.1454],\n",
       "        [0.5070],\n",
       "        [5.9809],\n",
       "        [1.8259],\n",
       "        [1.9270],\n",
       "        [1.7746],\n",
       "        [0.6440],\n",
       "        [2.9199],\n",
       "        [2.1627],\n",
       "        [2.8087],\n",
       "        [0.5281],\n",
       "        [1.1836],\n",
       "        [1.1430]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373e4251-313a-4234-95e8-284b0b5723b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e0fe88-fb98-42a5-87bc-4b8bb6a20acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c94a24-d796-49b0-8d80-157e195dcc48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9cc983-3fd7-4653-b44a-213b2421b130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a70d336-e1a5-437b-b4a0-f62fa8ab6935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beaea5b-e470-4aff-8341-4a3cb56a7c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44deaac-b461-4a67-b3de-bca1d77ab2cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8a3067-8dab-4091-a13f-9725832c6e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af6f8ac6-c47f-4d12-aaf4-201071231f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import numpy as jnp\n",
    "\n",
    "from flax import linen as nn\n",
    "\n",
    "from KANLayer import KANLayer\n",
    "\n",
    "\n",
    "layer_dims = [3, 5, 1]\n",
    "\n",
    "k = 3\n",
    "const_spl = False\n",
    "const_res = False\n",
    "residual = nn.swish\n",
    "noise_std = 0.1\n",
    "grid_e = 0.15\n",
    "\n",
    "\n",
    "layers = [KANLayer(n_in=layer_dims[i],\n",
    "                            n_out=layer_dims[i + 1],\n",
    "                            k=k,\n",
    "                            const_spl=const_spl,\n",
    "                            const_res=const_res,\n",
    "                            residual=residual,\n",
    "                            noise_std=noise_std,\n",
    "                            grid_e=grid_e) for i in range(len(layer_dims) - 1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0c317eb-1970-4805-807d-01adb7d7b9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KANLayer(\n",
       "     # attributes\n",
       "     n_in = 3\n",
       "     n_out = 5\n",
       "     k = 3\n",
       "     const_spl = False\n",
       "     const_res = False\n",
       "     residual = silu\n",
       "     noise_std = 0.1\n",
       "     grid_e = 0.15\n",
       " ),\n",
       " KANLayer(\n",
       "     # attributes\n",
       "     n_in = 5\n",
       "     n_out = 1\n",
       "     k = 3\n",
       "     const_spl = False\n",
       "     const_res = False\n",
       "     residual = silu\n",
       "     noise_std = 0.1\n",
       "     grid_e = 0.15\n",
       " )]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_params = self.scope.variables()['params']\n",
    "updated_state = self.scope.variables()['state']\n",
    "\n",
    "for i, layer in enumerate(self.layers):\n",
    "    # Extract the variables for the current layer\n",
    "    layer_variables = {\n",
    "        'params': updated_params[f'layers_{i}'],\n",
    "        'state': updated_state[f'layers_{i}']\n",
    "    }\n",
    "    \n",
    "    # Call the update_grid method on the current layer\n",
    "    coeffs, updated_layer_state = layer.apply(layer_variables, x, new_grid_size, method=layer.update_grid, mutable=['state'])\n",
    "    \n",
    "    # Update the state and parameters for the current layer\n",
    "    updated_state[f'layers_{i}'] = updated_layer_state['state']\n",
    "    updated_params[f'layers_{i}']['c_basis'] = coeffs\n",
    "\n",
    "return {'params': updated_params, 'state': updated_state}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc66b72-2e60-4cb0-9103-23dd803f62f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9dbbd2-b561-4140-8c84-1624a92277d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baa4c0c-98aa-4ce5-91f3-f78127efe20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_grids(self, x, G_new):\n",
    "    \"\"\"\n",
    "    Performs the grid update for each layer of the KAN architecture.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "        x (jnp.array): inputs for the first layer\n",
    "            shape (batch, self.layers[0])\n",
    "        G_new (int): Size of the new grid (in terms of intervals)\n",
    "\n",
    "    \"\"\"\n",
    "    # Here we must perform a loop over all layers and perform the update for each layer, while also tweaking the variables dict\n",
    "    # Note that between consecutive layers we must perform a forward pass to get the new value of x\n",
    "\n",
    "\n",
    "def __call__(self, x):\n",
    "    for i, layer in enumerate(self.layers):\n",
    "        x, spl_reshaped = layer(x)\n",
    "        if self.add_bias:\n",
    "            x += self.biases[i]\n",
    "    return x, spl_reshaped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
