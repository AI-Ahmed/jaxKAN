{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bbfd580-3381-4f9c-a5cd-8a6a6a627be8",
   "metadata": {},
   "source": [
    "# Full Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b25e86d-1419-4c35-b543-a15b926b77ac",
   "metadata": {},
   "source": [
    "This notebook contains a full example of training and evaluating a KAN model for a task. The task at hand is learning a multivariate function, namely\n",
    "\n",
    "$$ f\\left(x_1,x_2\\right) = \\exp\\left(\\sin\\left(\\pi x_1\\right) + x_2\\right) $$\n",
    "\n",
    "To do so, we will first generate some training samples, i.e. create an artificial dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5671ea0f-096b-4824-a6bd-2f629342abc4",
   "metadata": {},
   "source": [
    "## Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea58be3-4050-44f3-a7e6-3bf2885a9ec3",
   "metadata": {},
   "source": [
    "We randomly sample $N$ points from this function in the $\\left[-2,2\\right] \\times \\left[-2,2\\right]$ range. Some of them are retained for training, while the rest are used for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c685320-0c63-41d7-9d9c-8af55b2e11a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Define the true function\n",
    "def true_f(x_1,x_2):\n",
    "    return jnp.exp(jnp.sin(jnp.pi*x_1)+x_2)\n",
    "\n",
    "N = 5000\n",
    "\n",
    "# Randomly selected x_1, x_2 in [-2,2]\n",
    "x_1 = 4*jax.random.uniform(jax.random.PRNGKey(42), (N,)) - 2\n",
    "x_2 = 4*jax.random.uniform(jax.random.PRNGKey(43), (N,)) - 2\n",
    "\n",
    "# Get back ys\n",
    "y = true_f(x_1,x_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9c2cbc-c436-4f03-b302-ec8d07231842",
   "metadata": {},
   "source": [
    "We then use sklearn's built-in methods to split the \"dataset\" for training and testing. Of course this can be handled manually, but we're lazy. To run the following cell, we used `scikit-learn==1.4.2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55689393-574b-4b37-89fd-7e42e0dee773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Combine x_1 and x_2 into a single array\n",
    "X = jnp.stack((x_1, x_2), axis=-1)\n",
    "\n",
    "# Split the dataset into training and evaluation sets\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a72496-dd36-4e4d-90a6-0561e55ae973",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db1757f-c49b-4661-b52e-46e183f28618",
   "metadata": {},
   "source": [
    "We then define our data loaders to yield batches of data during training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "448423f3-3d69-4b5b-b22d-76bc3ebe1636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(X, y, batch_size, seed):\n",
    "    dataset_size = len(X)\n",
    "    indices = jax.random.permutation(jax.random.PRNGKey(seed), dataset_size)\n",
    "    \n",
    "    for start_idx in range(0, dataset_size, batch_size):\n",
    "        batch_indices = indices[start_idx:start_idx + batch_size]\n",
    "        yield X[batch_indices], y[batch_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f5b66ad-2580-4eb2-8541-f1c649895589",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 500\n",
    "train_loader = data_loader(X_train, y_train, batch, 42)\n",
    "eval_loader = data_loader(X_eval, y_eval, batch, 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc5e877-5e17-4aff-92d2-d0591703384e",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec01d3b-1ff1-4aba-98f2-f0fccc38d18d",
   "metadata": {},
   "source": [
    "With the data at hand, we proceed with the initialization of the necessary items. For the optimization part we will be using `optax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42c0b8f3-9e4d-416c-9619-80529c598eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "from flax import linen as nn\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "path_to_src = os.path.abspath(os.path.join(os.getcwd(), '../src'))\n",
    "if path_to_src not in sys.path:\n",
    "    sys.path.append(path_to_src)\n",
    "\n",
    "from KAN import KAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "332f9770-af4b-43ca-8e86-014edb6ec3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "layer_dims = [2, 5, 2, 1]\n",
    "model = KAN(layer_dims=layer_dims, k=3, add_bias=True)\n",
    "variables = model.init(key, jnp.ones([1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25fd925d-215b-470c-8950-80a98a4fa602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize optimizer\n",
    "learning_rate = 0.001\n",
    "optimizer = optax.adam(learning_rate)\n",
    "opt_state = optimizer.init(variables['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99061f4e-b294-4b7d-8b9b-f3140c9c0dbd",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d9d4b2-3ac7-4f5f-8ceb-912c198b31cc",
   "metadata": {},
   "source": [
    "This is the point where we need to define our loss function. For the predictions we simply use MSE Loss, while for the regularization we follow the arXiv preprint's direction and use the layer norms and entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b78aa8b-c967-4a42-8ffc-c15c14016075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(variables, x, y):\n",
    "    # Forward pass to acquire predictions and spl_regs\n",
    "    preds, spl_regs = model.apply(variables, x)\n",
    "\n",
    "    # Define the prediction loss\n",
    "    loss_pred = jnp.mean((preds-y)**2)\n",
    "    \n",
    "    # Define the regularization loss\n",
    "    loss_reg = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fbbb2d-6637-4ada-b08e-1fc7c6fce252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b030859a-8cfc-44cf-9d0d-acd97d90a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# $$ f\\left(x_1,x_2,x_3\\right) = \\left(x_1^2 + x_2^2\\right)^3\\cdot\\exp\\left(x_1 \\cdot x_3\\right) $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
